---
title: "Methods 2 -- Portfolio Assignment 3"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

- *Type:* Group assignment
- *Due:* 30 April 2023, 23:59
- *Instructions:* All problems are exercises from _Regression and Other Stories_. Please edit this file here and add your solutions.

# 1. Exercise 10.5

_Regression modeling and prediction:_ The folder `KidIQ` contains a subset of the children and mother data discussed earlier in the chapter. You have access to children’s test scores at age 3, mother’s education, and the mother’s age at the time she gave birth for a sample of 400 children.

```{r, echo = FALSE, include = FALSE}
#install.packages("rstanarm")
library("rstanarm")
library(ggplot2)
library(tidyverse)
library(car)
library(dplyr)
```

```{r}
#getwd()
data <- read.csv("data/child_iq.csv")
```


## (a) Fit a regression of child test scores on mother’s age, display the data and fitted model, check assumptions, and interpret the slope coefficient. 

### Based on this analysis, when do you recommend mothers should give birth? What are you assuming in making this recommendation?
Since the slope is positive, for every increase in mom age the ppvt increases by 0.85, indicating that giving birth at a later age is better due to the correlation of the values. 

((when using lm, the significance of the mom age variable is however only * and the R-squareds offered are very low, indicating that the variable is not a good explanation for the variance of the ppvt variable. This would imply that the correlation is likely not causation. I'm not aware of how to easily get this information out of stan_glm))
```{r}
model <- stan_glm(ppvt ~ momage, data = data, refresh = 0)
summary(model, digits = 2)

plot(data$momage, data$ppvt, xlab = "Mother's Age", ylab = "Test Scores", main = "Child test scores based on mother's age")
abline(model, col = "red")
```

```{r}
#spread of the data itself
summary(data)
densityPlot(data$ppvt)
densityPlot(data$educ_cat)
densityPlot(data$momage)
```
The level of mother education is particularly skewed towards level 2, with there being much fewer mothers with an education at level 4. The ppvt scores and the mother ages appear to be approximately normally distributed, meaning that if there is something that skews the data, this is very possibly the spread of education between mothers, with level 2 being particularly over-represented. That said, ppvt does have some skew towards lower scores, which may affect the results.

```{r}
#assumptions of the model
hist(model$resid) #a bit skewed but could probably be worse,likely due to all the mothers with education level 2

plot(fitted(model), resid(model), main = "Residuals vs Fitted",
     xlab = "Fitted values", ylab = "Residuals")
abline(h = 0, col = "red") #looks fairly pattern-less

qqnorm(model$resid)
qqline(model$resid) #a bit skewed but could probably be worse
```
Appears approximately normal enough with somewhat of a skew towards lower values, which may be due to the skew present in the data itself, in particular the education level of many of the mothers being at level 2 and a negative skew being present in the pptv scores of the babies.

## (b) Repeat this for a regression that further includes mother’s education, interpreting both slope coefficients in this model. Have your conclusions about the timing of birth changed?

The slope for education level of mother is much higher than that of her age, indicating that it has a much higher effect/correlation on the test scores of the baby than the age at which the mother gave birth, with one increase in education level of mother changing the ppvt by 4.7. Comparably, the age of the mother now has a very low positive slope of 0.34, indicating that it does not have a high effect on the score.

((Furthermore, lm summary has marked the variable as highly statistically significant with a low p-value (***, p ~ 0) and the R squared value has increased significantly by the addition of educ_cat, indicating that it explains a considerable amount of the variance of the baby test score variable.))
```{r}
model2 <- stan_glm(ppvt ~ momage + educ_cat, data = data, refresh = 0)

plot(data$momage, data$ppvt, xlab = "Mother's Age", ylab = "Test Scores")
abline(model2, col = "red")

summary(model2, digits = 2)
```


```{r}
#assumptions
hist(model2$resid)#a bit skewed but could probably be worse, likely due to all the mothers with education level 2

plot(fitted(model2), resid(model2), main = "Residuals vs Fitted",
     xlab = "Fitted values", ylab = "Residuals")
abline(h = 0, col = "red") #looks fairly patternless, even if the datapoints are somewhat concentrated around 85

qqnorm(model2$resid)
qqline(model2$resid) #a bit skewed but could probably be worse
```
Appears approximately normal enough with somewhat of a skew towards lower values, which may be due to the skew present in the data itself, in particular the education level of many of the mothers being at level 2 and a negative skew being present in the pptv scores of the babies.



## (c) Now create an indicator variable reflecting whether the mother has completed high school or not. Consider interactions between high school completion and mother’s age. Also create a plot that shows the separate regression lines for each high school completion status group.
HS completion appears to be more influential than age as an indicator of a higher test score for the baby, at least when viewed visually.
```{r}
data$high_school <- ifelse(data$educ_cat >= 2,1,0)
densityPlot(data$high_school) #most have graduated hs

#interaction between hs completion and age
model3 <- stan_glm(ppvt ~ momage * high_school, data = data, refresh = 0)
summary(model3, digits = 2)

ggplot(data, aes(x = momage, y = ppvt, color = as.factor(high_school))) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, aes(group = as.factor(high_school))) +
  labs(x = "Mother's Age", y = "Child Test score", color = "High School Completion") +
  theme_minimal()
```

## (d) Finally, fit a regression of child test scores on mother’s age and education level for the first 200 children and use this model to predict test scores for the next 200. Graphically display comparisons of the predicted and actual scores for the final 200 children.
```{r}
#data for training
data_train <- head(data, 200)
nrow(data_train)

#data for testing
data_test <- tail(data, 200)
nrow(data_test)

#just incase checking if there are common rows
intersect(row.names(data_train), row.names(data_test))

m_predict <- stan_glm(ppvt ~ momage + educ_cat, data = data_train, refresh = 0)
#summary(m_predict, digits = 2)

#predicting on the data_test
predicted_scores <- predict(m_predict, newdata = data_test)

df <- data.frame(real_scores = data_test$ppvt, predicted_scores = predicted_scores)

ggplot(df, aes(x = real_scores, y = predicted_scores)) +
  geom_point(aes(color = abs(real_scores - predicted_scores) < 10), size = 3) +
  scale_color_manual(values = c("red", "blue")) +
  labs(color = "Absolute Error < 10") +
  geom_abline(intercept = 0, slope = 1, linewidth = 1.5) +
  ggtitle("Predicted vs. Real Scores") +
  xlab("Real Scores") +
  ylab("Predicted Scores")

#its not very good at predicting? not a good model for it? did i do it right?
```

# 2. Exercise 10.6

_Regression models with interactions:_ The folder `Beauty` contains data (use file `beauty.csv`) from Hamermesh and Parker (2005) on student evaluations of instructors’ beauty and teaching quality for several courses at the University of Texas. The teaching evaluations were conducted at the end of the semester, and the beauty judgments were made later, by six students who had not attended the classes and were not aware of the course evaluations.

## (a) Run a regression using beauty (the variable `beauty`) to predict course evaluations (`eval`), adjusting for various other predictors. Graph the data and fitted model, and explain the meaning of each of the coefficients along with the residual standard deviation. Plot the residuals versus fitted values.
```{r}
beauty <- read.csv("data/beauty.csv")
```

```{r}
#putting in all the possible predictors
b1 <- stan_glm(eval ~ beauty + female + age + minority + nonenglish + lower + course_id, data = beauty, refresh = 0)
#b11 <- lm(eval ~ beauty + female + age + minority + nonenglish + lower + course_id, data = beauty) #i dont quite understand the benefit of using stan_glm yet, so will use both

summary(b1)
#summary(b11) #the R squared is pathetically small, beauty and female are according to summary statistically significant, although taking into account their small effects & low R-squared i'd wager they're not particularly meaningful?

#graphing the data
ggplot(beauty, aes(x=beauty, y=eval)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE, color="red", formula = y~x) +
  labs(x="Beauty", y="Evaluation Score") +
  ggtitle("Graphing Beauty & Evaluation Score")
```
I fit a model which included all the predictors with no interactions. The intercept is 4.2, meaning that when all the predictors are at their "default" value, or constant, the evaluation is 4.2. The "beauty" coefficient being at 0.1 indicates that when other predictors are held constant and the beauty value is increased by 1 unit, then the evaluation goes up by 0.1. The predictor "lower", whether the instructor is an instructor of a lower-class division course, has a similar effect due to the same coefficient 0.1 . "age" and 
"course_id" appear to have no effect on course evaluation due to the coefficients being 0, at least not according to this model. Whether the instructor is female, a minority and a non-english speaker has a negative effect on the course evaluation, with the coefficients being -0.2, -0.1, -0.3 respectively (when the other predictors are held constant). 
The sigma value is 0.5, meaning that the average difference between observed values and predicted values is 0.5 units.


## (b) Fit some other models, including beauty and also other predictors. Consider at least one model with interactions. For each model, explain the meaning of each of its estimated coefficients.

See also Felton, Mitchell, and Stinson (2003) for more on this topic.
```{r}
m1 <- stan_glm(eval ~ beauty + female + minority + nonenglish, data = beauty, refresh = 0)
m2 <- stan_glm(eval ~ beauty + female + nonenglish + age, data = beauty, refresh = 0)
m3 <- stan_glm(eval ~ beauty*female + minority + nonenglish, data = beauty, refresh = 0)
m4 <- stan_glm(eval ~ beauty + beauty*female + minority*nonenglish, data = beauty, refresh = 0)

#lm for my own sake
# l1 <- lm(eval ~ beauty + female + minority + nonenglish, data = beauty)
# l2 <- lm(eval ~ beauty + female + nonenglish + age, data = beauty)
# l3 <- lm(eval ~ beauty*female + minority + nonenglish, data = beauty)
# l4 <- lm(eval ~ beauty + beauty*female + minority*nonenglish, data = beauty)

summary(m1)
summary(m2)
summary(m3)
summary(m4)

# summary(l1)
# summary(l2)
# summary(l3)
# summary(l4)

```
### 1. model 1 (m1) is a simple model featuring no interactions (eval ~ beauty + female + minority + nonenglish). 
It's intercept is 4.1, meaning that when all the predictors are held constant, the evaluation value is 4.1. 
In this model, "beauty" has a coefficient of 0.2, meaning that by an increase in "beauty" by 1 unit, the evaluation goes up by 0.2, provided all the other predictors are held constant. 
"female" has a coefficient of -0.2, meaning that an increase in "female" by 1 unit, or rather, if the instructor is female, they are going to have an evaluation lower by -0.2, provided the other predictors are held constant.
"nonenglish", -0.3, if the instructor is not a native speaker of english. If other predictors are held constant, then this means that the evaluation will go down by -0.3. 
In this model minority seems to have no effect.
Sigma is 0.5, the average difference between observed values and predicted values is 0.5 units.

### 2. model 2 (m2) is another simple model featuring no interactions (eval ~ beauty + female + nonenglish + age)
Intercept 4.2, when all predictors are held constant the evaluation value is 4.2.
"beauty" 0.2, when beauty increases by one unit and all the other predictors are held constant, evaluation increases by 0.2
"female" -0.2, when female increases by one unit (= instructor is a woman) and all the other predictors are held constant, evaluation decreases by 0.2
"nonenglish" -0.3, when nonenglish increases by one unit (= instructor is not a native speaker), and all the other predicotrs are held constant, evaluation decreases by 0.3.
"age" 0, age seems to have no correlation with evaluation value.
sigma 0.5,  the average difference between observed values and predicted values is 0.5 units.


### 3. model 3 (m3) is a model featuring an interaction between beauty and gender (eval ~ beauty*female + minority + nonenglish)
Intercept is 4.1
"beauty" 0.2
"female" -0.2
minority 0.0
nonenglish -0.3
beauty:female -0.1, this variable represents the interaction effect between beauty and whether the instructor is a woman on the response variable "eval". By having an interaction like this, we can see whether the effect of beauty on the response variable differs based on whether the instructor is male or female.
sigma 0.5

beauty:female represents the interaction effect between the beauty and female predictor variables on the response variable (eval). An interaction effect means that the effect of one predictor on the response variable is different depending on the level of another predictor, allowing for different slopes. Beauty on it's own, when other predictors are held constant, has an effect/correlation of 0.2 points per increase in unit. When other values are held constant, "female" is at its base value, which is male. Meaning that the interaction effect in this case showcases the effect of beauty when the gender of the instructor is female, the coefficient of which is -0.1 + 2.0 = 1.0. It appears beauty is "more beneficial" towards male teachers when it comes to increasing their evaluation score, at least according to this model.

### 4. model 4 (m4) is a model featuring an interaction between beauty & gender and minority & nonenglish (eval ~ beauty + beauty*female + minority*nonenglish
Intercept is 4.1
"beauty" 0.2
"female" -0.2
minority 0.0
nonenglish -0.2
beauty:female -0.1
minority:nonenglish -0.2
sigma 0.5

minority:nonenglish is an interaction variable which represents the interaction between "minority" and "nonenglish", giving a different slope and intercept for the response variable based on the 4 possible combinations of "minority" and "nonenglish".

The coefficients are to be interpreted as follows:

minority:nonenglish coefficient = difference in the effect of being a non-English speaking minority compared to being a non-English speaking non-minority on the evaluation score --> both a minority and not a native english speaker (-0.2) 

minority coefficient = difference in minority value while all other values are held constant --> minority but a native english speaker (0.0, no effect)

nonenglish coefficient = difference in nonenglish value while all other values are held constant --> not a minority but is a non-native english speaker (-0.2)

Intercept = evaluation score for non-minority non-English speaking instructors.

It appears that being a non-native english speaker has a negative effect on evaluation score while whether someone is a minority doesn't appear to matter according to this model.

# 3. Exercise 10.7

_Predictive simulation for linear regression:_ Take one of the models from the previous exercise.

## (a) Instructor A is a 50-year-old woman who is a native English speaker and has a beauty score of -1. Instructor B is a 60-year-old man who is a native English speaker and has a beauty score of -0.5. Simulate 1000 random draws of the course evaluation rating of these two instructors. In your simulation, use posterior_predict to account for the uncertainty in the regression parameters as well as predictive uncertainty.
```{r}
#chosen model (since minority is not mentioned in the simulated instructors)
m2 <- stan_glm(eval ~ beauty + female + nonenglish + age, data = beauty, refresh = 0)

instr_a <- data.frame(age = 50, nonenglish = 0, beauty = -1, female = 1)
instr_b <- data.frame(age = 60, nonenglish = 0, beauty = -0.5, female = 0)

set.seed(123)
sim_a <- posterior_predict(m2, newdata = instr_a, n.sims = 1000)
sim_b <- posterior_predict(m2, newdata = instr_b, n.sims = 1000)

```

## (b) Make a histogram of the difference between the course evaluations for A and B. What is the probability that A will have a higher evaluation?
37.6%
```{r}
diff_evals <- sim_a - sim_b
hist(diff_evals, breaks = 20, col = "lightblue", xlab = "Difference in evaluations",
     main = "Histogram of differences between course evaluations for A and B")

prob_a_better <- mean(diff_evals > 0)
cat("The probability that A will have a higher evaluation than B is", (round(prob_a_better, 3))*100, "%")
```

